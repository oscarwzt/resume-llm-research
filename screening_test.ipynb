{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "import subprocess\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/Users/oscarwan/Desktop/NYU/Research/CodeAndData/parsed_resume_jsons/parsed_resumes_llama2_new.json\", \"r\") as f:\n",
    "    resumes = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10708"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(resumes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['20196.txt',\n",
       " '19184.txt',\n",
       " '19696.txt',\n",
       " '18301.txt',\n",
       " '23087.txt',\n",
       " '20249.txt',\n",
       " '10766.txt',\n",
       " '00658.txt',\n",
       " '00750.txt',\n",
       " '00132.txt',\n",
       " '27642.txt',\n",
       " '18315.txt',\n",
       " '17798.txt',\n",
       " '11513.txt',\n",
       " '01370.txt',\n",
       " '14398.txt',\n",
       " '19636.txt',\n",
       " '15756.txt',\n",
       " '22223.txt',\n",
       " '06145.txt',\n",
       " '27616.txt',\n",
       " '25861.txt',\n",
       " '22274.txt',\n",
       " '21197.txt',\n",
       " '19871.txt',\n",
       " '03515.txt',\n",
       " '22782.txt',\n",
       " '19666.txt',\n",
       " '22525.txt',\n",
       " '01732.txt',\n",
       " '27627.txt',\n",
       " '19009.txt',\n",
       " '20632.txt',\n",
       " '17005.txt',\n",
       " '14141.txt',\n",
       " '00607.txt',\n",
       " '13815.txt',\n",
       " '20102.txt',\n",
       " '27050.txt',\n",
       " '19633.txt',\n",
       " '19852.txt',\n",
       " '14149.txt',\n",
       " '18304.txt',\n",
       " '28990.txt']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern = re.compile(r'\\bmachine[-\\s]?learning\\b|\\bml\\b', re.IGNORECASE)\n",
    "\n",
    "# Search for the desired skills within each resume\n",
    "matches = []\n",
    "for key, resume in resumes.items():\n",
    "    #print(key)\n",
    "    skills = resume.get(\"Skills\", []) + resume.get(\"Technical_Skills\", [])\n",
    "    for skill in skills:\n",
    "        if type(skill) == str and pattern.search(skill):\n",
    "            matches.append(key)\n",
    "            break\n",
    "\n",
    "matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Data Analyst Data Analyst Data Analyst Passionate about using analytics and data science to help companies deliver an outstanding customer experience to every- customer. Work Experience Data Analyst Illinois Institute of Chicago - Chicago, IL August 2018 to May 2019 Increasing number of alumni gifts is crucial for any university, performed data extraction using SQL, data- transformation & data validation ( python) on alumni's data generated by Raiser's Edge.- * Built data pipeline by performing data cleaning, exploratory data analysis (EDA), feature engineering, data pre- processing.- * Developed donor segmentation algorithm using machine learning model which increased the number of donors by- 23%.- * Used Decision trees, Random-Forest, Support-Vector Machine, Naive-Bayes classifier to group the donors in a segment depending on the income. Performed model evaluation and achieved an accuracy of 87%.- * Built interactive dashboards using Tableau to identify trends in the gifts received in form of pledge/credit-card. Team Lead April 2017 to July 2017 * Led a team of five software engineers to analyze root cause of issues and developed solutions generating company- $150,000 dollars.- * Provided training to the cross-functional team of 25 engineers to build effective data visualizations using tableau. Software Engineer / Data Analytics Engineer LTI-Larsen & Toubro InfoTech - IN June 2015 to July 2017 * Performed data-extraction, transformation and loading - (ETL) development and programming.- * Performed ad hoc analysis for large volumes of data including structured and unstructured data.- * Worked closely with analytical researchers, data scientist and solution architects to develop an analytical framework- to perform effective data analysis on terabytes of data.- * Increased the project's revenue by 17% after analyzing the issues and adopting a proactive approach to resolve the issues.- * Managed coordination with 10 team members for designing and developing data models for various clients.- * Familiar with the workings of Hadoop, Map Reduce, Pyspark, AWS infrastructure & cloud services.- * Re-engineered and automated daily tasks like creating user profiles, assigning approval routes using macros to reduce- manpower by 25 hours/week.- * Built Tableau dashboards to identify trends in financial data and presented the resulting insights to stakeholders that- increased the performance of team by 33.3%.- * Developed documentation for best practices followed for ad hoc analysis and machine learning pipelines. Data Analyst Bank of Baroda - Mumbai, Maharashtra July 2014 to March 2015 * Used Logistic Regression & Random Forest to analyze the sales & to predict the performance of the second quarter.- * Designed SQL & Python scripts to extract & analyze internal & external data sources to identify different trends.- * Worked with various client facing teams to execute predictive modelling using Spark & Hadoop.- * Analyzed the reports & helped to identify various data trends & market findings.- * Worked with undefined & changing ideas & business problems with unstructured raw data. Python Developer Intern Tarun Mitra Mandal - Mumbai, Maharashtra January 2014 to May 2014 Wrote python code to perform data extraction, data transformation and data validation on list of donors. Build- python scripts to automate data processing steps on excel sheets.- * Developed and implemented data analyses, data collection systems and other strategies that optimize statistical- efficiency and quality. SQL Developer Intern Bank of Baroda - Mumbai, Maharashtra February 2012 to July 2012 * Performed data migrations and schema alterations for customer database.- * Automated database management tasks by developing SQL triggers and procedures reducing manpower by 15- hrs/week.- * Developed SQL statements to perform database transaction management- * Created SQL join queries to combine data from multiple tables depending on use-cases- * Built and maintained SQL scripts, indexes, and complex queries for data analysis and extraction for varied projects Education Master of Science in Computer Science Illinois Institute of Technology August 2017 to May 2019 Bachelor of Science in Computer Engineering UNIVERSITY OF MUMBAI August 2012 to May 2015 Skills Hdfs, Oozie, Sqoop, Kafka, Flume, Lda, Machine learning, Map reduce, Natural language processing, Power bi, Anova, Association rules, K-means, Logistic regression, Pca, Random forest, Visual studio, Git, Hive, Natural, SQL Links http://linkedin.com/in/pooja-ym-mehta http://github.com/pmehta27 Additional Information SKILLS- Programming: Python, R Programming, Java, Linux- Bash Shell Scripting- Database: Oracle, MySQL, MSSQL, TSQL, PLSQL, PostgreSQL, SQLite- Statistics: Hypothesis Testing, Normal Distribution, T Test, Z Test, P Test, F Test, Anova, Central- Limit Theorem, AB Testing- Big Data Skills: HDFS, Map Reduce, Spark, Hive, Kafka, Sqoop, Flume, Spark Streaming, Zookeeper,- Oozie, Zappelin, Hue- Machine Learning Libraries: Pandas, Numpy, Scikit learn, Matplotlib, Seaborn, Plotly, SparkML, OpenCV, Tensorflow,- Keras- Data Modelling & Evaluation: K-Means, KNN, Logistic Regression, Decision Tree, Random Forest Classifier, Support- Vector Machines, Natural Language Processing, Deep Neural Nets, Reinforcement- Learning, PCA, LDA, Time Series, Forecasting, Text Analysis, Association Rules,- Supervised & Unsupervised Machine Learning- Cloud Skills: AWS - EC2, Redshift, RDS, S3, Auto scaling, Cloud Front, SQS, SNS, Google Cloud- Analytics & Visualization Tools: Tableau, Power BI- Platforms/IDE: MSSQL Server 2014, Visual Studio, Hortonworks Sandbox, Jupyter, Eclipse, Git- Development Methodologies: Agile, Scrum- Soft Skills: Analytical and Problem Solving, Optimistic, Leadership, Communication, Organizing and\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getCleanResume(matches[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "resume_research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
